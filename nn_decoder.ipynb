{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyMq9ieVDoboOdcbBEx+2dCO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install stim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CEcWXzzUFILX","executionInfo":{"status":"ok","timestamp":1702263712633,"user_tz":480,"elapsed":8508,"user":{"displayName":"Mohammad Alam","userId":"02216870806600081877"}},"outputId":"87d763e2-205a-4078-bbcf-0968ca34e2da"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting stim\n","  Downloading stim-1.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stim) (1.23.5)\n","Installing collected packages: stim\n","Successfully installed stim-1.12.1\n"]}]},{"cell_type":"markdown","source":["Imports"],"metadata":{"id":"TOUrdwRq1YXF"}},{"cell_type":"code","execution_count":52,"metadata":{"id":"B1xlI4qVsJxh","executionInfo":{"status":"ok","timestamp":1702276848268,"user_tz":480,"elapsed":677,"user":{"displayName":"Mohammad Alam","userId":"02216870806600081877"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","import torch\n","import stim\n","import os\n"]},{"cell_type":"markdown","source":["Create circuit and sample data"],"metadata":{"id":"1o1vB52N1cUV"}},{"cell_type":"code","source":["class preparecktandsample(object):\n","    def __init__(self, code_size, rounds=2):\n","        self.rounds = rounds\n","        self.code_size = code_size\n","        self.code_type = \"surface_code:rotated_memory_z\"\n","        self.num_x_stabilizers = (int(self.code_size/2)+1)*(self.code_size-1)\n","        self.num_z_stabilizers = self.num_x_stabilizers\n","        self.num_stabilizers = self.num_x_stabilizers + self.num_z_stabilizers\n","\n","    def setnoisevectors(self, probvector, \\\n","                        clifford_noise=False, \\\n","                        reset_flip_prob=False, \\\n","                        measure_flip_prob=False, \\\n","                        round_data_noise=False):\n","        self.clifford_noise = []\n","        self.reset_flip_prob = []\n","        self.measure_flip_prob = []\n","        self.round_data_noise = []\n","        self.probvector = probvector\n","        for p in probvector:\n","            if not clifford_noise:\n","                self.clifford_noise.append(p)\n","            else:\n","                self.clifford_nose.append(0.0)\n","            if not reset_flip_prob:\n","                self.reset_flip_prob.append(p)\n","            else:\n","                self.reset_flip_prob.append(0.0)\n","            if not measure_flip_prob:\n","                self.measure_flip_prob.append(p)\n","            else:\n","                self.measure_flip_prob.append(0.0)\n","            if not round_data_noise:\n","                self.round_data_noise.append(p)\n","            else:\n","                self.round_data_noise.append(0.0)\n","\n","    def createcircuits(self):\n","        self.circuits = []\n","        for i,v in enumerate(self.probvector):\n","            ckt = stim.Circuit.generated(\n","                    self.code_type,\n","                    rounds=self.rounds, distance=self.code_size,\n","                    after_clifford_depolarization=self.clifford_noise[i],\n","                    after_reset_flip_probability=self.reset_flip_prob[i],\n","                    before_measure_flip_probability=self.measure_flip_prob[i],\n","                    before_round_data_depolarization=self.round_data_noise[i])\n","            self.circuits.append(ckt)\n","\n","    def customreshape(self, samples):\n","        M = self.code_size+1\n","        images = []\n","        for kk in range(samples.shape[0]):\n","            t = np.zeros((M,M), dtype=np.float32)\n","            t[0,1:-1:2] = samples[kk,0:int((self.code_size-1)/2)]\n","            k = 1\n","            l = 1\n","            st = int((self.code_size-1)/2)\n","            for i in range(self.code_size-1):\n","                t[l,k:k+self.code_size] = samples[kk,st:st+self.code_size]\n","                st = st+self.code_size\n","                if l%2 == 1:\n","                    k = 0\n","                else:\n","                    k = 1\n","                l += 1\n","            t[M-1,2:-1:2] = samples[kk,st:]\n","            padn = int((24-(self.code_size+1)*2)/2)\n","            images.append(\n","                np.pad(\n","                    np.kron(t, np.ones((2,2))).astype(np.float32),\n","                    pad_width=[(padn,padn),(padn,padn)],\n","                    mode='constant'\n","                    )\n","                )\n","        return images\n","\n","    def sampledata(self, numdata):\n","        self.createcircuits()\n","        numsnaps = int(numdata/len(self.circuits))\n","        snapshots = []\n","        labels = []\n","        for circuit in self.circuits:\n","            sampler = circuit.compile_detector_sampler()\n","            start = self.num_z_stabilizers + (self.rounds-2)*self.num_stabilizers\n","            for i in range(2):\n","                snapshots_one_class = []\n","                labels_one_class = []\n","                while len(snapshots_one_class) < numsnaps/2:\n","                    res = int(numsnaps/2)\n","                    lsamples, obs = sampler.sample(shots = res, separate_observables = True)\n","                    lsamples = lsamples[np.where(obs==i)[0]]\n","                    obs = obs[np.where(obs==i)[0]]\n","                    if lsamples.shape[0] < 1:\n","                        continue\n","                    lsamples = lsamples[:, start:start+self.num_stabilizers]\n","                    non_empty_indices = (np.sum(lsamples, axis=1)!=0)\n","                    reshapedsnapshots = self.customreshape(lsamples[non_empty_indices, :])\n","                    snapshots_one_class.extend(reshapedsnapshots)\n","                    labels_one_class.extend(obs[non_empty_indices, :].astype(np.uint8))\n","                    res = numsnaps - len(snapshots)\n","                snapshots.extend(snapshots_one_class)\n","                labels.extend(labels_one_class)\n","        X = np.stack(snapshots, axis=0)\n","        y =  np.stack(labels, axis=0)\n","        perm = np.random.permutation(X.shape[0])\n","        return [X[perm], y[perm]]"],"metadata":{"id":"m0RO7hR51RoE","executionInfo":{"status":"ok","timestamp":1702276851733,"user_tz":480,"elapsed":318,"user":{"displayName":"Mohammad Alam","userId":"02216870806600081877"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["Create tensor dataset from numpy arrays"],"metadata":{"id":"J7ZT6KGO-DVB"}},{"cell_type":"code","source":["class CustomTensorDataset(Dataset):\n","    def __init__(self, dataset, transform_list=None):\n","        [data_X, data_y] = dataset\n","        X_tensor, y_tensor = torch.tensor(data_X), torch.tensor(data_y)\n","        tensors = (X_tensor, y_tensor)\n","        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n","        self.tensors = tensors\n","        self.transforms = transform_list\n","\n","    def __getitem__(self, index):\n","        x = self.tensors[0][index]\n","        if self.transforms:\n","            x = self.transforms(x)\n","        y = self.tensors[1][index]\n","        return torch.unsqueeze(x, 0), y.float()\n","\n","    def __len__(self):\n","        return self.tensors[0].size(0)"],"metadata":{"id":"E7YWz8-Z9746","executionInfo":{"status":"ok","timestamp":1702276859186,"user_tz":480,"elapsed":248,"user":{"displayName":"Mohammad Alam","userId":"02216870806600081877"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["A linear NN to sweep hyper parameter of depth and size of dense layers"],"metadata":{"id":"DzNkZYg9-NgU"}},{"cell_type":"code","source":["class Netlin1(nn.Module):\n","    def __init__(self, sizefirst):\n","        super(Netlin1, self).__init__()\n","        self.linlayers = nn.ModuleList()\n","        self.linlayers.append(nn.Linear(1*24*24,sizefirst))\n","        p1 = sizefirst\n","        p2 = int(p1/2)\n","        while p2 >= 128:\n","            self.linlayers.append(nn.Linear(p1,p2))\n","            p1 = p2\n","            p2 = int(p2/2)\n","        self.linlayers.append(nn.Linear(128,1))\n","\n","    def forward(self, x):\n","        x = x.view(-1, 24*24)\n","        for i, l in enumerate(self.linlayers):\n","            if i == len(self.linlayers)-1:\n","                break\n","            x = torch.relu(self.linlayers[i](x))\n","            x = torch.relu(x)\n","        x = self.linlayers[-1](x)\n","        x = torch.sigmoid(x)\n","        return x"],"metadata":{"id":"ZIWMgCPI-LN6","executionInfo":{"status":"ok","timestamp":1702276863813,"user_tz":480,"elapsed":590,"user":{"displayName":"Mohammad Alam","userId":"02216870806600081877"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["A linear NN to sweep hyper parameter of size of dense layers"],"metadata":{"id":"pT9U5wkg-anW"}},{"cell_type":"code","source":["class Netlin2(nn.Module):\n","    def __init__(self, sizefirst):\n","        super(Netlin2, self).__init__()\n","        self.linlayers = nn.ModuleList()\n","        self.linlayers.append(nn.Linear(1*24*24,sizefirst))\n","        p1 = sizefirst\n","        p2 = int(p1/2)\n","        self.linlayers.append(nn.Linear(p1,128))\n","        self.linlayers.append(nn.Linear(128,1))\n","\n","    def forward(self, x):\n","        x = x.view(-1, 24*24)\n","        for i, l in enumerate(self.linlayers):\n","            if i == len(self.linlayers)-1:\n","                break\n","            x = torch.relu(self.linlayers[i](x))\n","            x = torch.relu(x)\n","        x = self.linlayers[-1](x)\n","        x = torch.sigmoid(x)\n","        return x"],"metadata":{"id":"sPSXiJLn-Mhb","executionInfo":{"status":"ok","timestamp":1702276866914,"user_tz":480,"elapsed":260,"user":{"displayName":"Mohammad Alam","userId":"02216870806600081877"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["class Netconv(nn.Module):\n","    def __init__(self, code_distance, num_outchannels, filter_size):\n","        super(Netconv, self).__init__()\n","        self.code_distance = code_distance\n","        self.num_outchannels = num_outchannels\n","        self.filter_size = filter_size\n","        oc = self.num_outchannels\n","        fz = self.filter_size\n","        self.conv1 = nn.Conv2d(1, oc, fz)\n","        self.conv2 = nn.Conv2d(oc, oc*2, fz)\n","        self.conv3 = nn.Conv2d(oc*2, oc*4, fz)\n","        if fz == 3:\n","            self.mpool = nn.MaxPool2d(6, 6)\n","            fv = oc*4*3*3\n","        elif fz == 5:\n","            self.mpool = nn.MaxPool2d(4, 4)\n","            fv = oc*4*3*3\n","        elif fz == 7:\n","            self.mpool = nn.MaxPool2d(2, 2)\n","            fv = oc*4*3*3\n","        self.fv = fv\n","        if self.code_distance == 5:\n","            self.fc1 = nn.Linear(fv, 512)\n","            self.fc2 = nn.Linear(512, 128)\n","            self.fc3 = nn.Linear(128, 1)\n","        elif self.code_distance == 7:\n","            self.fc1 = nn.Linear(fv, 1024)\n","            self.fc2 = nn.Linear(1024, 512)\n","            self.fc3 = nn.Linear(512, 128)\n","            self.fc4 = nn.Linear(128, 1)\n","        elif self.code_distance == 9:\n","            self.fc1 = nn.Linear(fv, 2048)\n","            self.fc2 = nn.Linear(2048, 1024)\n","            self.fc3 = nn.Linear(1024, 512)\n","            self.fc4 = nn.Linear(512, 128)\n","            self.fc5 = nn.Linear(128, 1)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.conv1(x))\n","        x = torch.relu(self.conv2(x))\n","        x = torch.relu(self.conv3(x))\n","        x = self.mpool(x)\n","        x = x.view(-1, self.fv)\n","        if self.code_distance == 5:\n","            x = torch.relu(self.fc1(x))\n","            x = torch.relu(self.fc2(x))\n","            x = self.fc3(x)\n","        elif self.code_distance == 7:\n","            x = torch.relu(self.fc1(x))\n","            x = torch.relu(self.fc2(x))\n","            x = torch.relu(self.fc3(x))\n","            x = self.fc4(x)\n","        elif self.code_distance == 9:\n","            x = torch.relu(self.fc1(x))\n","            x = torch.relu(self.fc2(x))\n","            x = torch.relu(self.fc3(x))\n","            x = torch.relu(self.fc4(x))\n","            x = self.fc5(x)\n","        x = torch.sigmoid(x)\n","        return x"],"metadata":{"id":"3P_aV3feikke","executionInfo":{"status":"ok","timestamp":1702276869175,"user_tz":480,"elapsed":259,"user":{"displayName":"Mohammad Alam","userId":"02216870806600081877"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["A top level function to train a model based on data sampled from quantum circuits"],"metadata":{"id":"RXNnyuV4_4ao"}},{"cell_type":"code","source":["def trainmodel(model, code_distance, probs, training_instances, testloader, optimizer, criterion, numepochs, device, batchsize=32, valinterval=1):\n","    train_loss_history = []\n","    train_acc_history = []\n","    val_loss_history = []\n","    val_acc_history = []\n","    num = 0\n","    num_images = 0\n","    epochelapsed = 0\n","    samplingobj = preparecktandsample(code_distance)\n","    samplingobj.setnoisevectors(probs, round_data_noise=True)\n","\n","    train_loss = 0.0\n","    train_acc = 0.0\n","    val_loss = 0.0\n","    val_acc = 0.0\n","    epochcounter = 0\n","    for epoch in range(numepochs):\n","        trainset = CustomTensorDataset(dataset = samplingobj.sampledata(training_instances))\n","        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize, shuffle=True, num_workers=0)\n","        model.train()\n","        for i, data in enumerate(trainloader, 0):\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","            train_acc += ((outputs>0.5) == labels).sum().item()\n","            num_images += labels.size(0)\n","            print(\"\\r images processed: {} and epoch {}\".format(num_images, epoch+1), end='')\n","\n","        epochcounter += 1\n","        if epochcounter == valinterval:\n","            train_loss /= (len(trainloader)*epochcounter)\n","            train_loss_history.append(train_loss)\n","            train_acc /= (len(trainloader.dataset)*epochcounter)\n","            train_acc_history.append(train_acc)\n","\n","            model.eval()\n","            with torch.no_grad():\n","                for inputs, labels in testloader:\n","                    inputs, labels = inputs.to(device), labels.to(device)\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","                    val_loss += loss.item()\n","                    val_acc += ((outputs > 0.5) == labels).sum().item()\n","            val_loss /= len(testloader)\n","            val_loss_history.append(val_loss)\n","            val_acc /= len(testloader.dataset)\n","            val_acc_history.append(val_acc)\n","\n","            epochcounter = 0\n","            train_loss = 0.0\n","            train_acc = 0.0\n","            val_loss = 0.0\n","            val_acc = 0.0\n","\n","    print(\"\")\n","    return [train_loss_history, train_acc_history, val_loss_history, val_acc_history]"],"metadata":{"id":"sUjW68vr_C1C","executionInfo":{"status":"ok","timestamp":1702276874745,"user_tz":480,"elapsed":238,"user":{"displayName":"Mohammad Alam","userId":"02216870806600081877"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["def sweeplayercount(code_distance, ntype=\"lin1\", directory=\"denselayer\" ):\n","    os.makedirs(directory, exist_ok=True)\n","    fname1 = os.path.join(directory, \"loss_accuracy_{}_{}.csv\".format(code_distance, ntype))\n","    fname2 = os.path.join(directory, \"loss_accuracy_{}_{}.png\".format(code_distance, ntype))\n","    probs = [0.001, 0.005, 0.01, 0.1]\n","    training_data_size = len(probs)*10000\n","    test_data_size = len(probs)*1000\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    epochs = 30\n","    samplingobjtest = preparecktandsample(code_distance)\n","    samplingobjtest.setnoisevectors(probs, round_data_noise=True)\n","    testset = CustomTensorDataset(dataset = samplingobjtest.sampledata(test_data_size))\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)\n","    criterion = nn.BCELoss()\n","    sizes = [256, 512, 1024, 2048, 2048*2, 2048*2*2]\n","    g1 = []\n","    g2 = []\n","    g3 = []\n","    g4 = []\n","    fout1 = open(fname1, 'w')\n","    fout1.write(\"SIZE,TRAIN-LOSS,VAL-LOSS,TRAIN-ACCURACY,VAL-ACCURACY\\n\")\n","    for size in sizes:\n","        if ntype==\"lin1\":\n","            net = Netlin1(size)\n","        elif ntype==\"lin2\":\n","            net = Netlin2(size)\n","        net.to(device)\n","        optimizer = optim.Adam(net.parameters(), lr=0.0001)\n","        [y1, y2, y3, y4] = trainmodel(net, code_distance, probs, \\\n","                   training_data_size, testloader, \\\n","                   optimizer, criterion, epochs, device)\n","        g1.append(y1[-1])\n","        g2.append(y2[-1])\n","        g3.append(y3[-1])\n","        g4.append(y4[-1])\n","        fout1.write(\"{},{},{},{},{}\\n\".format(size, y1[-1], y3[-1], y2[-1], y4[-1]))\n","    fout1.close()\n","    fig, axes = plt.subplots(nrows=2, ncols=1)\n","    axes[0].plot(sizes, g1, label='train loss')\n","    axes[0].plot(sizes, g3, label='val loss')\n","    axes[0].set_xlabel(\"Size\")\n","    axes[0].set_ylabel(\"Loss\")\n","    axes[0].legend()\n","    axes[1].plot(sizes, g2, label='train Accuracy')\n","    axes[1].plot(sizes, g4, label='val Accuracy')\n","    axes[1].set_xlabel(\"Size\")\n","    axes[1].set_ylabel(\"Accuracy\")\n","    axes[1].legend()\n","    plt.savefig(fname2)\n","    plt.show()"],"metadata":{"id":"EZvBkmJEAEoo","executionInfo":{"status":"ok","timestamp":1702276881246,"user_tz":480,"elapsed":256,"user":{"displayName":"Mohammad Alam","userId":"02216870806600081877"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["def sweepconvchannel(code_distance, directory=\"convelayer\" ):\n","    os.makedirs(directory, exist_ok=True)\n","    fname1 = os.path.join(directory, \"loss_accuracy_vs_outchannel_{}.csv\".format(code_distance))\n","    fname2 = os.path.join(directory, \"loss_accuracy_vs_outchannel_{}.png\".format(code_distance))\n","    probs = [0.001, 0.005, 0.01, 0.1]\n","    training_data_size = len(probs)*10000\n","    test_data_size = len(probs)*1000\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    epochs = 30\n","    samplingobjtest = preparecktandsample(code_distance)\n","    samplingobjtest.setnoisevectors(probs, round_data_noise=True)\n","    testset = CustomTensorDataset(dataset = samplingobjtest.sampledata(test_data_size))\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)\n","    criterion = nn.BCELoss()\n","    num_channels = [12, 24, 48]\n","    g1 = []\n","    g2 = []\n","    g3 = []\n","    g4 = []\n","    fout1 = open(fname1, 'w')\n","    fout1.write(\"NUM_CHANNELS,TRAIN-LOSS,VAL-LOSS,TRAIN-ACCURACY,VAL-ACCURACY\\n\")\n","    for nc in num_channels:\n","        net = Netconv(code_distance, nc, 5)\n","        net.to(device)\n","        optimizer = optim.Adam(net.parameters(), lr=0.0001)\n","        [y1, y2, y3, y4] = trainmodel(net, code_distance, probs, \\\n","                   training_data_size, testloader, \\\n","                   optimizer, criterion, epochs, device)\n","        g1.append(y1[-1])\n","        g2.append(y2[-1])\n","        g3.append(y3[-1])\n","        g4.append(y4[-1])\n","        fout1.write(\"{},{},{},{},{}\\n\".format(nc, y1[-1], y3[-1], y2[-1], y4[-1]))\n","    fout1.close()\n","    fig, axes = plt.subplots(nrows=2, ncols=1)\n","    axes[0].plot(num_channels, g1, label='train loss')\n","    axes[0].plot(num_channels, g3, label='val loss')\n","    axes[0].set_xlabel(\"Num Channels\")\n","    axes[0].set_ylabel(\"Loss\")\n","    axes[0].legend()\n","    axes[1].plot(num_channels, g2, label='train Accuracy')\n","    axes[1].plot(num_channels, g4, label='val Accuracy')\n","    axes[1].set_xlabel(\"Num Channels\")\n","    axes[1].set_ylabel(\"Accuracy\")\n","    axes[1].legend()\n","    plt.savefig(fname2)\n","    plt.show()"],"metadata":{"id":"NmMq1EFuUK2o","executionInfo":{"status":"ok","timestamp":1702276887879,"user_tz":480,"elapsed":271,"user":{"displayName":"Mohammad Alam","userId":"02216870806600081877"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["def sweepconvfiltersize(code_distance, directory=\"convelayer\" ):\n","    os.makedirs(directory, exist_ok=True)\n","    fname1 = os.path.join(directory, \"loss_accuracy_vs_filtersizes_{}.csv\".format(code_distance))\n","    fname2 = os.path.join(directory, \"loss_accuracy_vs_filtersizes_{}.png\".format(code_distance))\n","    probs = [0.001, 0.005, 0.01, 0.1]\n","    training_data_size = len(probs)*10000\n","    test_data_size = len(probs)*1000\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    epochs = 20\n","    samplingobjtest = preparecktandsample(code_distance)\n","    samplingobjtest.setnoisevectors(probs, round_data_noise=True)\n","    testset = CustomTensorDataset(dataset = samplingobjtest.sampledata(test_data_size))\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)\n","    criterion = nn.BCELoss()\n","    filter_sizes = [3, 5, 7]\n","    g1 = []\n","    g2 = []\n","    g3 = []\n","    g4 = []\n","    fout1 = open(fname1, 'w')\n","    fout1.write(\"NUM_CHANNELS,TRAIN-LOSS,VAL-LOSS,TRAIN-ACCURACY,VAL-ACCURACY\\n\")\n","    for fz in filter_sizes:\n","        net = Netconv(code_distance, 24, fz)\n","        net.to(device)\n","        optimizer = optim.Adam(net.parameters(), lr=0.0001)\n","        [y1, y2, y3, y4] = trainmodel(net, code_distance, probs, \\\n","                   training_data_size, testloader, \\\n","                   optimizer, criterion, epochs, device)\n","        g1.append(y1[-1])\n","        g2.append(y2[-1])\n","        g3.append(y3[-1])\n","        g4.append(y4[-1])\n","        fout1.write(\"{},{},{},{},{}\\n\".format(fz, y1[-1], y3[-1], y2[-1], y4[-1]))\n","    fout1.close()\n","    fig, axes = plt.subplots(nrows=2, ncols=1)\n","    axes[0].plot(filter_sizes, g1, label='train loss')\n","    axes[0].plot(filter_sizes, g3, label='val loss')\n","    axes[0].set_xlabel(\"Filter sizes\")\n","    axes[0].set_ylabel(\"Loss\")\n","    axes[0].legend()\n","    axes[1].plot(filter_sizes, g2, label='train Accuracy')\n","    axes[1].plot(filter_sizes, g4, label='val Accuracy')\n","    axes[1].set_xlabel(\"Filter sizes\")\n","    axes[1].set_ylabel(\"Accuracy\")\n","    axes[1].legend()\n","    plt.savefig(fname2)\n","    plt.show()"],"metadata":{"id":"kv_8sPiOyxRK","executionInfo":{"status":"ok","timestamp":1702276891946,"user_tz":480,"elapsed":242,"user":{"displayName":"Mohammad Alam","userId":"02216870806600081877"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["def sweepbatch(code_distance, directory=\"batchsize\" ):\n","    os.makedirs(directory, exist_ok=True)\n","    fname1 = os.path.join(directory, \"loss_accuracy_vs_batchsizes_{}.csv\".format(code_distance))\n","    fname2 = os.path.join(directory, \"loss_accuracy_vs_batchrsizes_{}.png\".format(code_distance))\n","    probs = [0.001, 0.005, 0.01, 0.1]\n","    training_data_size = len(probs)*10000\n","    test_data_size = len(probs)*1000\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    epochs = 20\n","    samplingobjtest = preparecktandsample(code_distance)\n","    samplingobjtest.setnoisevectors(probs, round_data_noise=True)\n","    testset = CustomTensorDataset(dataset = samplingobjtest.sampledata(test_data_size))\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)\n","    criterion = nn.BCELoss()\n","    batch_sizes = [16, 24, 32, 48]\n","    g1 = []\n","    g2 = []\n","    g3 = []\n","    g4 = []\n","    fout1 = open(fname1, 'w')\n","    fout1.write(\"BATCH_SIZES,TRAIN-LOSS,VAL-LOSS,TRAIN-ACCURACY,VAL-ACCURACY\\n\")\n","    for bs in batch_sizes:\n","        net = Netconv(code_distance, 24, 7)\n","        net.to(device)\n","        optimizer = optim.Adam(net.parameters(), lr=0.0001)\n","        [y1, y2, y3, y4] = trainmodel(net, code_distance, probs, \\\n","                   training_data_size, testloader, \\\n","                   optimizer, criterion, epochs, device, batchsize=bs)\n","        g1.append(y1[-1])\n","        g2.append(y2[-1])\n","        g3.append(y3[-1])\n","        g4.append(y4[-1])\n","        fout1.write(\"{},{},{},{},{}\\n\".format(bs, y1[-1], y3[-1], y2[-1], y4[-1]))\n","    fout1.close()\n","    fig, axes = plt.subplots(nrows=2, ncols=1)\n","    axes[0].plot(batch_sizes, g1, label='train loss')\n","    axes[0].plot(batch_sizes, g3, label='val loss')\n","    axes[0].set_xlabel(\"Batch sizes\")\n","    axes[0].set_ylabel(\"Loss\")\n","    axes[0].legend()\n","    axes[1].plot(batch_sizes, g2, label='train Accuracy')\n","    axes[1].plot(batch_sizes, g4, label='val Accuracy')\n","    axes[1].set_xlabel(\"Batch sizes\")\n","    axes[1].set_ylabel(\"Accuracy\")\n","    axes[1].legend()\n","    plt.savefig(fname2)\n","    plt.show()"],"metadata":{"id":"TXNEYjIq2iIT","executionInfo":{"status":"ok","timestamp":1702276897545,"user_tz":480,"elapsed":263,"user":{"displayName":"Mohammad Alam","userId":"02216870806600081877"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["def sweeplr(code_distance, directory=\"Learnrate\" ):\n","    os.makedirs(directory, exist_ok=True)\n","    fname1 = os.path.join(directory, \"loss_accuracy_vs_lr_{}.csv\".format(code_distance))\n","    fname2 = os.path.join(directory, \"loss_accuracy_vs_lr_{}.png\".format(code_distance))\n","    probs = [0.001, 0.005, 0.01, 0.1]\n","    training_data_size = len(probs)*10000\n","    test_data_size = len(probs)*1000\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    epochs = 20\n","    samplingobjtest = preparecktandsample(code_distance)\n","    samplingobjtest.setnoisevectors(probs, round_data_noise=True)\n","    testset = CustomTensorDataset(dataset = samplingobjtest.sampledata(test_data_size))\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)\n","    criterion = nn.BCELoss()\n","    learning_rates = [0.01, 0.005, 0.001, 0.0005, 0.0001]\n","    g1 = []\n","    g2 = []\n","    g3 = []\n","    g4 = []\n","    fout1 = open(fname1, 'w')\n","    fout1.write(\"LR,TRAIN-LOSS,VAL-LOSS,TRAIN-ACCURACY,VAL-ACCURACY\\n\")\n","    for lrv in learning_rates:\n","        net = Netconv(code_distance, 24, 7)\n","        net.to(device)\n","        optimizer = optim.Adam(net.parameters(), lr=lrv)\n","        [y1, y2, y3, y4] = trainmodel(net, code_distance, probs, \\\n","                   training_data_size, testloader, \\\n","                   optimizer, criterion, epochs, device, batchsize=48)\n","        g1.append(y1[-1])\n","        g2.append(y2[-1])\n","        g3.append(y3[-1])\n","        g4.append(y4[-1])\n","        fout1.write(\"{},{},{},{},{}\\n\".format(lrv, y1[-1], y3[-1], y2[-1], y4[-1]))\n","    fout1.close()\n","    fig, axes = plt.subplots(nrows=2, ncols=1)\n","    axes[0].plot(learning_rates, g1, label='train loss')\n","    axes[0].plot(learning_rates, g3, label='val loss')\n","    axes[0].set_xlabel(\"Learning Rate\")\n","    axes[0].set_ylabel(\"Loss\")\n","    axes[0].legend()\n","    axes[1].plot(learning_rates, g2, label='train Accuracy')\n","    axes[1].plot(learning_rates, g4, label='val Accuracy')\n","    axes[1].set_xlabel(\"Learning Rate\")\n","    axes[1].set_ylabel(\"Accuracy\")\n","    axes[1].legend()\n","    plt.savefig(fname2)\n","    plt.show()"],"metadata":{"id":"kL3H1QpSND6k","executionInfo":{"status":"ok","timestamp":1702283621399,"user_tz":480,"elapsed":563,"user":{"displayName":"Mohammad Alam","userId":"02216870806600081877"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["sweeplr(7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"btgGFXV98lnB","outputId":"96a459ca-4911-4e2a-ae51-9e9e2bb680c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" images processed: 987741 and epoch 20\n"," images processed: 994297 and epoch 20\n"," images processed: 999735 and epoch 20\n"," images processed: 968194 and epoch 20"]}]}]}